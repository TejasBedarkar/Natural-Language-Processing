{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e82ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its uses in :\n",
    "    \n",
    "    \n",
    "# Tokenization\n",
    "# POS\n",
    "# NER(named entity)\n",
    "# Dependancy parsing\n",
    "# Lemmatization\n",
    "# Stope words removal\n",
    "# Word vector \n",
    "# Text Classification\n",
    "# Text Similarity\n",
    "# Customization\n",
    "# Efficiency\n",
    "# Support for multiple languages \n",
    "# integration with ml pipelines\n",
    "# Community and Documentation\n",
    "# named Entity Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06605b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f5a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCY | PROPN\n",
      "is | AUX\n",
      "an | DET\n",
      "awesome | ADJ\n",
      "NLP | PROPN\n",
      "library | NOUN\n",
      ". | PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"spaCY is an awesome NLP library.\"\n",
    "doc=nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,'|',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524f74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP | ORG\n"
     ]
    }
   ],
   "source": [
    "# NER(named entity)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"|\",ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca49deb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dependancy parsing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token\u001b[38;5;241m.\u001b[39mtext , token\u001b[38;5;241m.\u001b[39mdep_ , token\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mtext , text\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mpos_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Dependancy parsing\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text , token.dep_ , token.head.text , text.head.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bfb98",
   "metadata": {},
   "source": [
    "Advanced NLP Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763eccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity 0.5099376221161971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23764\\431889825.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity=word1.similarity(word2)\n"
     ]
    }
   ],
   "source": [
    "# Word vector and similarity\n",
    "\n",
    "word1=nlp('king')\n",
    "word2=nlp('queen')\n",
    "similarity=word1.similarity(word2)\n",
    "print(\"Similarity\",similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5820b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
